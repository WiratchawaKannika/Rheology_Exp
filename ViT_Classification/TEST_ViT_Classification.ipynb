{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "orange-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fewer-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 19:04:10.324510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-24 19:04:10.425966: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-24 19:04:10.898938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/kannika/miniconda3/envs/tf/lib/\n",
      "2023-10-24 19:04:10.898993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/kannika/miniconda3/envs/tf/lib/\n",
      "2023-10-24 19:04:10.898997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/kannika/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###############------------#######################\n",
    "from vit_keras import vit, utils\n",
    "from vit_keras import layers as vit_layer \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import typing\n",
    "import warnings\n",
    "import typing_extensions as tx\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import glob, warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import callbacks\n",
    "from keras.callbacks import Callback\n",
    "import imageio\n",
    "from tensorflow import keras\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "systematic-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southeast-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir):\n",
    "        import time\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "        return os.path.join(root_logdir,run_id)\n",
    "\n",
    "    \n",
    "def avoid_error(gen):\n",
    "     while True:\n",
    "        try:\n",
    "            data, labels = next(gen)\n",
    "            yield data, labels\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "###### ViT model with the functional ######\n",
    "###########################################\n",
    "\n",
    "def build_ViTModel(fine_tune, IMAGE_SIZE, Numclass):\n",
    "    if Numclass == 1:\n",
    "        activation_fun = 'sigmoid'\n",
    "    elif Numclass == 3:\n",
    "        activation_fun = 'softmax'\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    :param fine_tune (bool): Whether to train the hidden layers or not. \n",
    "                   Numclass: Number of Class to train ; Default Numclass=1\n",
    "    \"\"\"\n",
    "    \n",
    "    vit_model = vit.vit_b32(image_size=IMAGE_SIZE, classes=Numclass, activation=activation_fun, pretrained = True, \n",
    "                            include_top = False, pretrained_top = False)\n",
    "    print('[INFO]: Loading pre-trained weights')\n",
    "    x = vit_model.get_layer('ExtractToken').output\n",
    "    ### add the tail layer ###  \n",
    "    Flatten_layer1 = layers.Flatten()(x)\n",
    "    BatchNormalization_layer1 = layers.BatchNormalization(name='BatchNormalization_1')(Flatten_layer1)\n",
    "    Dense_layer = layers.Dense(64, activation='gelu',name='Dense_1')(BatchNormalization_layer1)\n",
    "    Dense_layer1 = layers.Dense(32, activation='gelu',name='Dense_2')(Dense_layer)\n",
    "    BatchNormalization_layer2 = layers.BatchNormalization(name='BatchNormalization_2')(Dense_layer1)\n",
    "    Dense_layer2 = layers.Dense(Numclass, activation=activation_fun, name='Pred_blood')(BatchNormalization_layer2)\n",
    "        \n",
    "    model = models.Model(inputs= vit_model.input, outputs=[Dense_layer2], name = 'ViT_BloodClass') \n",
    "    \n",
    "    print('This is the number of trainable layers '\n",
    "          'before freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "    if fine_tune:\n",
    "        print('[INFO]: Freezing hidden layers...')\n",
    "        for layer in vit_model.layers:\n",
    "            layer.trainable = False\n",
    "        print('This is the number of trainable layers '\n",
    "                  'after freezing the conv base:', len(model.trainable_weights))\n",
    "    print('-'*100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generous-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "_fold = f\"fold{fold}\"\n",
    "classname = 'typeBEvsBM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corresponding-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset set: 168 2dFFT images\n",
      "[INFO]: For Train Set : With Shape (112, 16)\n",
      "[INFO]: For Validation Set : With Shape (56, 16)\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "#data_path = \"/home/kannika/code/Rheology2023/Rheology_Blood/Dataset_Rheology_Blood_Viscosity_HN_NBL-2dFFTdataset-3channels-6Fold-splitclass.csv\"\n",
    "data_path = \"/home/kannika/code/Rheology2023/Rheology_Blood/Dataset_Blood_Viscosity-2dFFTdataset-3channels-3Fold-EMClasses.csv\"\n",
    "df_2dFFT = pd.read_csv(data_path)\n",
    "print(f\"Dataset set: {df_2dFFT.shape[0]} 2dFFT images\")\n",
    "DFtrain = df_2dFFT[df_2dFFT['fold']!=fold].reset_index(drop=True)\n",
    "DFvalid = df_2dFFT[df_2dFFT['fold']==fold].reset_index(drop=True)\n",
    "## Split train, validation set\n",
    "#DFtrain, DFvalid = split_valid_train(train_2dFFT)\n",
    "print(f\"[INFO]: For Train Set : With Shape {DFtrain.shape}\")\n",
    "print(f\"[INFO]: For Validation Set : With Shape {DFvalid.shape}\")\n",
    "### Get data Loder\n",
    "### Get data Loader\n",
    "if classname == \"thalas3classes\":\n",
    "    numclass = 3\n",
    "    colums_y = \"subclass\"\n",
    "    class_mode_img = 'categorical'\n",
    "    loss_smooth = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2)\n",
    "    metrics_acc = 'accuracy'\n",
    "elif classname == \"thalas2classes\":\n",
    "    numclass = 1\n",
    "    colums_y = \"classes_binary\"\n",
    "    class_mode_img = 'raw'\n",
    "    loss_smooth = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.2)\n",
    "    metrics_acc = 'binary_accuracy'\n",
    "elif classname == \"typeBEvsBM\":\n",
    "    numclass = 1\n",
    "    colums_y = \"typeBEvsBM_binary\"\n",
    "    class_mode_img = 'raw'\n",
    "    loss_smooth = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.2)\n",
    "    metrics_acc = 'binary_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "assisted-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2dFFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "neural-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(df_2dFFT[\"classes_binary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "understanding-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 384\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "alternate-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get data Loder\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                    rotation_range=20,\n",
    "                    brightness_range=[0.5, 1.5],\n",
    "                    shear_range=0.5,\n",
    "                    horizontal_flip = False,\n",
    "                    fill_mode = 'nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "def Data_generator(IMAGE_SIZE, BATCH_SIZE, DFtrain, DFvalid, colums_y, class_mode_img):\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "                    dataframe = DFtrain,\n",
    "                    directory = None,\n",
    "                    x_col = 'image_path',\n",
    "                    y_col = colums_y,\n",
    "                    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    color_mode= 'rgb',\n",
    "                    class_mode =class_mode_img)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "                    dataframe = DFvalid,\n",
    "                    directory = None,\n",
    "                    x_col = 'image_path',\n",
    "                    y_col = colums_y,\n",
    "                    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    color_mode= 'rgb',\n",
    "                    class_mode=class_mode_img)\n",
    "    \n",
    "    return train_generator, test_generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automatic-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 validated image filenames.\n",
      "Found 56 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator = Data_generator(IMAGE_SIZE, BATCH_SIZE, DFtrain, DFvalid, colums_y, class_mode_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "modern-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "knowing-venice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.05882353, 0.0627451 , 0.07450981],\n",
       "         [0.05490196, 0.0627451 , 0.0627451 ],\n",
       "         [0.05882353, 0.06666667, 0.0509804 ],\n",
       "         ...,\n",
       "         [0.06666667, 0.0627451 , 0.05882353],\n",
       "         [0.0627451 , 0.0627451 , 0.05882353],\n",
       "         [0.05882353, 0.0627451 , 0.05490196]],\n",
       "\n",
       "        [[0.0627451 , 0.0627451 , 0.07450981],\n",
       "         [0.05490196, 0.0627451 , 0.06666667],\n",
       "         [0.05882353, 0.06666667, 0.0509804 ],\n",
       "         ...,\n",
       "         [0.0509804 , 0.0627451 , 0.0509804 ],\n",
       "         [0.04705883, 0.0627451 , 0.0509804 ],\n",
       "         [0.03921569, 0.06666667, 0.05490196]],\n",
       "\n",
       "        [[0.0627451 , 0.0627451 , 0.07058824],\n",
       "         [0.05490196, 0.0627451 , 0.07450981],\n",
       "         [0.05490196, 0.06666667, 0.05490196],\n",
       "         ...,\n",
       "         [0.03529412, 0.06666667, 0.05882353],\n",
       "         [0.04313726, 0.06666667, 0.05882353],\n",
       "         [0.0509804 , 0.0627451 , 0.05882353]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03137255, 0.0627451 , 0.0627451 ],\n",
       "         [0.03529412, 0.0627451 , 0.05882353],\n",
       "         [0.03921569, 0.0627451 , 0.05882353],\n",
       "         ...,\n",
       "         [0.05882353, 0.06666667, 0.07450981],\n",
       "         [0.05490196, 0.06666667, 0.07058824],\n",
       "         [0.0509804 , 0.05490196, 0.0627451 ]],\n",
       "\n",
       "        [[0.04705883, 0.0627451 , 0.0627451 ],\n",
       "         [0.0509804 , 0.0627451 , 0.0627451 ],\n",
       "         [0.05882353, 0.0627451 , 0.06666667],\n",
       "         ...,\n",
       "         [0.05882353, 0.07058824, 0.07450981],\n",
       "         [0.05490196, 0.06666667, 0.07450981],\n",
       "         [0.05490196, 0.05882353, 0.06666667]],\n",
       "\n",
       "        [[0.05882353, 0.0509804 , 0.06666667],\n",
       "         [0.05882353, 0.04705883, 0.07058824],\n",
       "         [0.05882353, 0.03921569, 0.07058824],\n",
       "         ...,\n",
       "         [0.05882353, 0.07058824, 0.06666667],\n",
       "         [0.05882353, 0.06666667, 0.07450981],\n",
       "         [0.05490196, 0.0627451 , 0.06666667]]],\n",
       "\n",
       "\n",
       "       [[[0.07058824, 0.09411766, 0.10196079],\n",
       "         [0.07843138, 0.09803922, 0.10980393],\n",
       "         [0.08627451, 0.10196079, 0.09411766],\n",
       "         ...,\n",
       "         [0.07058824, 0.09411766, 0.10196079],\n",
       "         [0.07058824, 0.09411766, 0.10196079],\n",
       "         [0.07058824, 0.09411766, 0.09803922]],\n",
       "\n",
       "        [[0.07058824, 0.09411766, 0.10588236],\n",
       "         [0.07843138, 0.09411766, 0.10588236],\n",
       "         [0.08235294, 0.10196079, 0.09803922],\n",
       "         ...,\n",
       "         [0.07058824, 0.09411766, 0.09411766],\n",
       "         [0.07450981, 0.09803922, 0.09411766],\n",
       "         [0.07450981, 0.10196079, 0.09411766]],\n",
       "\n",
       "        [[0.06666667, 0.09411766, 0.10980393],\n",
       "         [0.07843138, 0.09411766, 0.10588236],\n",
       "         [0.08235294, 0.10196079, 0.10588236],\n",
       "         ...,\n",
       "         [0.07843138, 0.1137255 , 0.09411766],\n",
       "         [0.07843138, 0.1137255 , 0.09411766],\n",
       "         [0.07450981, 0.1137255 , 0.09411766]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.07843138, 0.08627451, 0.09019608],\n",
       "         [0.07843138, 0.09019608, 0.09019608],\n",
       "         [0.07843138, 0.09411766, 0.09019608],\n",
       "         ...,\n",
       "         [0.06666667, 0.09803922, 0.08235294],\n",
       "         [0.07058824, 0.09411766, 0.09803922],\n",
       "         [0.07843138, 0.10196079, 0.09411766]],\n",
       "\n",
       "        [[0.08235294, 0.09803922, 0.07843138],\n",
       "         [0.08235294, 0.09803922, 0.07843138],\n",
       "         [0.08627451, 0.09803922, 0.07450981],\n",
       "         ...,\n",
       "         [0.06666667, 0.09803922, 0.07843138],\n",
       "         [0.07058824, 0.09411766, 0.09411766],\n",
       "         [0.07450981, 0.09803922, 0.09803922]],\n",
       "\n",
       "        [[0.08627451, 0.09019608, 0.08235294],\n",
       "         [0.08627451, 0.08627451, 0.08627451],\n",
       "         [0.08627451, 0.08235294, 0.09019608],\n",
       "         ...,\n",
       "         [0.0627451 , 0.09411766, 0.07843138],\n",
       "         [0.07058824, 0.09803922, 0.09019608],\n",
       "         [0.07450981, 0.09803922, 0.09803922]]],\n",
       "\n",
       "\n",
       "       [[[0.1137255 , 0.11764707, 0.1254902 ],\n",
       "         [0.1137255 , 0.1254902 , 0.12941177],\n",
       "         [0.1254902 , 0.1254902 , 0.14117648],\n",
       "         ...,\n",
       "         [0.1137255 , 0.13333334, 0.1254902 ],\n",
       "         [0.1137255 , 0.14509805, 0.1254902 ],\n",
       "         [0.11764707, 0.16470589, 0.1254902 ]],\n",
       "\n",
       "        [[0.11764707, 0.09411766, 0.11764707],\n",
       "         [0.11764707, 0.09411766, 0.1137255 ],\n",
       "         [0.11764707, 0.10588236, 0.11764707],\n",
       "         ...,\n",
       "         [0.1137255 , 0.13333334, 0.1254902 ],\n",
       "         [0.1137255 , 0.15294118, 0.1254902 ],\n",
       "         [0.1254902 , 0.16470589, 0.1254902 ]],\n",
       "\n",
       "        [[0.1137255 , 0.10588236, 0.15294118],\n",
       "         [0.1137255 , 0.10196079, 0.14509805],\n",
       "         [0.11764707, 0.09411766, 0.12941177],\n",
       "         ...,\n",
       "         [0.1137255 , 0.14117648, 0.1254902 ],\n",
       "         [0.11764707, 0.15686275, 0.1254902 ],\n",
       "         [0.14117648, 0.15294118, 0.12941177]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10196079, 0.16862746, 0.13333334],\n",
       "         [0.08235294, 0.13333334, 0.14509805],\n",
       "         [0.11764707, 0.12941177, 0.15294118],\n",
       "         ...,\n",
       "         [0.10588236, 0.1254902 , 0.14509805],\n",
       "         [0.10588236, 0.13333334, 0.14509805],\n",
       "         [0.10588236, 0.14117648, 0.14509805]],\n",
       "\n",
       "        [[0.08235294, 0.16862746, 0.14509805],\n",
       "         [0.09019608, 0.11764707, 0.14509805],\n",
       "         [0.13333334, 0.14509805, 0.15686275],\n",
       "         ...,\n",
       "         [0.10588236, 0.11764707, 0.14117648],\n",
       "         [0.10588236, 0.1137255 , 0.14117648],\n",
       "         [0.10588236, 0.1137255 , 0.14509805]],\n",
       "\n",
       "        [[0.08235294, 0.15294118, 0.14509805],\n",
       "         [0.10196079, 0.1137255 , 0.14509805],\n",
       "         [0.14509805, 0.15686275, 0.15686275],\n",
       "         ...,\n",
       "         [0.1137255 , 0.12941177, 0.12941177],\n",
       "         [0.1137255 , 0.12941177, 0.12941177],\n",
       "         [0.10588236, 0.12941177, 0.13333334]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.09019608, 0.10196079, 0.10980393],\n",
       "         [0.08627451, 0.10588236, 0.10980393],\n",
       "         [0.08627451, 0.10196079, 0.10588236],\n",
       "         ...,\n",
       "         [0.07843138, 0.09803922, 0.10588236],\n",
       "         [0.08235294, 0.09803922, 0.10196079],\n",
       "         [0.08235294, 0.09803922, 0.10588236]],\n",
       "\n",
       "        [[0.08627451, 0.09019608, 0.10196079],\n",
       "         [0.09411766, 0.09019608, 0.10196079],\n",
       "         [0.09411766, 0.09803922, 0.10588236],\n",
       "         ...,\n",
       "         [0.08235294, 0.09803922, 0.10980393],\n",
       "         [0.08235294, 0.09803922, 0.10196079],\n",
       "         [0.07843138, 0.10196079, 0.10588236]],\n",
       "\n",
       "        [[0.07058824, 0.08627451, 0.08627451],\n",
       "         [0.06666667, 0.08627451, 0.08627451],\n",
       "         [0.07450981, 0.08627451, 0.09019608],\n",
       "         ...,\n",
       "         [0.08235294, 0.09803922, 0.10588236],\n",
       "         [0.08235294, 0.09803922, 0.10196079],\n",
       "         [0.06666667, 0.10196079, 0.10196079]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.08627451, 0.07843138, 0.09019608],\n",
       "         [0.10196079, 0.08627451, 0.08235294],\n",
       "         [0.09411766, 0.08235294, 0.07450981],\n",
       "         ...,\n",
       "         [0.07450981, 0.09411766, 0.09411766],\n",
       "         [0.08235294, 0.10196079, 0.10196079],\n",
       "         [0.08235294, 0.09803922, 0.10196079]],\n",
       "\n",
       "        [[0.09411766, 0.07843138, 0.09803922],\n",
       "         [0.10196079, 0.09019608, 0.07843138],\n",
       "         [0.09019608, 0.07843138, 0.07450981],\n",
       "         ...,\n",
       "         [0.05490196, 0.07058824, 0.07058824],\n",
       "         [0.0509804 , 0.06666667, 0.06666667],\n",
       "         [0.05882353, 0.07843138, 0.07843138]],\n",
       "\n",
       "        [[0.10196079, 0.08235294, 0.09411766],\n",
       "         [0.09803922, 0.09019608, 0.07450981],\n",
       "         [0.08627451, 0.07843138, 0.07843138],\n",
       "         ...,\n",
       "         [0.08235294, 0.08627451, 0.09411766],\n",
       "         [0.07450981, 0.08235294, 0.08627451],\n",
       "         [0.06666667, 0.07843138, 0.07843138]]],\n",
       "\n",
       "\n",
       "       [[[0.10588236, 0.14901961, 0.14901961],\n",
       "         [0.10980393, 0.14901961, 0.14901961],\n",
       "         [0.11764707, 0.14901961, 0.14509805],\n",
       "         ...,\n",
       "         [0.10588236, 0.13333334, 0.16862746],\n",
       "         [0.11764707, 0.13333334, 0.14509805],\n",
       "         [0.09411766, 0.15686275, 0.14509805]],\n",
       "\n",
       "        [[0.11764707, 0.12156864, 0.13333334],\n",
       "         [0.11764707, 0.1254902 , 0.13333334],\n",
       "         [0.10980393, 0.1254902 , 0.13725491],\n",
       "         ...,\n",
       "         [0.10980393, 0.13333334, 0.16862746],\n",
       "         [0.11764707, 0.13333334, 0.14509805],\n",
       "         [0.09411766, 0.15686275, 0.14509805]],\n",
       "\n",
       "        [[0.12156864, 0.1254902 , 0.14901961],\n",
       "         [0.12156864, 0.1254902 , 0.14509805],\n",
       "         [0.12156864, 0.1254902 , 0.14509805],\n",
       "         ...,\n",
       "         [0.10980393, 0.13333334, 0.16862746],\n",
       "         [0.11764707, 0.13333334, 0.14509805],\n",
       "         [0.09803922, 0.15686275, 0.14509805]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.11764707, 0.14901961, 0.16862746],\n",
       "         [0.1254902 , 0.11764707, 0.13725491],\n",
       "         [0.12156864, 0.10980393, 0.13725491],\n",
       "         ...,\n",
       "         [0.1254902 , 0.09803922, 0.11764707],\n",
       "         [0.1254902 , 0.10588236, 0.11764707],\n",
       "         [0.1254902 , 0.11764707, 0.10980393]],\n",
       "\n",
       "        [[0.12156864, 0.15686275, 0.16862746],\n",
       "         [0.1254902 , 0.10980393, 0.13725491],\n",
       "         [0.12156864, 0.10980393, 0.13725491],\n",
       "         ...,\n",
       "         [0.13725491, 0.09803922, 0.14509805],\n",
       "         [0.13333334, 0.08627451, 0.13725491],\n",
       "         [0.13333334, 0.08235294, 0.13725491]],\n",
       "\n",
       "        [[0.1254902 , 0.14901961, 0.16862746],\n",
       "         [0.1254902 , 0.10980393, 0.13725491],\n",
       "         [0.11764707, 0.10980393, 0.13725491],\n",
       "         ...,\n",
       "         [0.12156864, 0.13333334, 0.15686275],\n",
       "         [0.13333334, 0.13333334, 0.15686275],\n",
       "         [0.13725491, 0.13333334, 0.15686275]]],\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.15294118, 0.14509805],\n",
       "         [0.13725491, 0.15294118, 0.14509805],\n",
       "         [0.13725491, 0.16078432, 0.14509805],\n",
       "         ...,\n",
       "         [0.11764707, 0.16470589, 0.1254902 ],\n",
       "         [0.08235294, 0.10196079, 0.12941177],\n",
       "         [0.14901961, 0.1137255 , 0.13725491]],\n",
       "\n",
       "        [[0.13333334, 0.12941177, 0.13333334],\n",
       "         [0.13333334, 0.12941177, 0.13333334],\n",
       "         [0.13333334, 0.13333334, 0.13333334],\n",
       "         ...,\n",
       "         [0.11764707, 0.16862746, 0.1254902 ],\n",
       "         [0.08235294, 0.09803922, 0.12941177],\n",
       "         [0.14901961, 0.1137255 , 0.13725491]],\n",
       "\n",
       "        [[0.1137255 , 0.10980393, 0.1137255 ],\n",
       "         [0.1137255 , 0.10980393, 0.11764707],\n",
       "         [0.1137255 , 0.10980393, 0.11764707],\n",
       "         ...,\n",
       "         [0.11764707, 0.16862746, 0.1254902 ],\n",
       "         [0.08235294, 0.09803922, 0.13333334],\n",
       "         [0.15294118, 0.11764707, 0.14509805]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12941177, 0.14509805, 0.13725491],\n",
       "         [0.12941177, 0.10980393, 0.11764707],\n",
       "         [0.10196079, 0.12941177, 0.14509805],\n",
       "         ...,\n",
       "         [0.1137255 , 0.13725491, 0.1254902 ],\n",
       "         [0.1137255 , 0.13725491, 0.1254902 ],\n",
       "         [0.1137255 , 0.13725491, 0.12941177]],\n",
       "\n",
       "        [[0.12941177, 0.14509805, 0.13333334],\n",
       "         [0.1254902 , 0.10980393, 0.11764707],\n",
       "         [0.10196079, 0.13333334, 0.14509805],\n",
       "         ...,\n",
       "         [0.09411766, 0.10196079, 0.13725491],\n",
       "         [0.09411766, 0.10980393, 0.13725491],\n",
       "         [0.09411766, 0.10980393, 0.13725491]],\n",
       "\n",
       "        [[0.12941177, 0.14509805, 0.13333334],\n",
       "         [0.1254902 , 0.10980393, 0.11764707],\n",
       "         [0.10196079, 0.13333334, 0.14509805],\n",
       "         ...,\n",
       "         [0.1254902 , 0.12941177, 0.14901961],\n",
       "         [0.1254902 , 0.1254902 , 0.14901961],\n",
       "         [0.1254902 , 0.1254902 , 0.14901961]]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "critical-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "mobile-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "comprehensive-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/media/tohn/HDD/rheology2023/ViTModel/Classification/Blood_Viscosity\"\n",
    "name = \"3_classes\" ## Set ---------------\n",
    "root_base = f\"{savedir}/{name}\"\n",
    "R = 1\n",
    "_R = f\"R{R}\"\n",
    "## Set mkdir TensorBoard \n",
    "tensorName = \"TensorBoard\"\n",
    "root_logdir = f\"{root_base}/{_fold}/{_R}/{tensorName}\"\n",
    "os.makedirs(root_logdir, exist_ok=True)\n",
    "### Run TensorBoard \n",
    "run_logdir = get_run_logdir(root_logdir)\n",
    "tensorboard_cb = callbacks.TensorBoard(log_dir=run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "subject-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up model path\n",
    "modelNamemkdir = f\"{root_base}/{_fold}/{_R}/models\"\n",
    "os.makedirs(modelNamemkdir, exist_ok=True)\n",
    "modelName  = f\"ViTb32_{numclass}Class_{_fold}_{_R}.h5\"\n",
    "Model2save = f'{modelNamemkdir}/{modelName}'\n",
    "\n",
    "root_Metrics = f'{root_base}/{_fold}/{_R}/on_epoch_end/'\n",
    "os.makedirs(root_Metrics, exist_ok=True)\n",
    "\n",
    "class Metrics(Callback):\n",
    "        def on_epoch_end(self, epochs, logs={}):\n",
    "            self.model.save(f'{root_Metrics}{modelName}')\n",
    "            return\n",
    "# For tracking Quadratic Weighted Kappa score and saving best weights\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "refined-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading pre-trained weights\n",
      "This is the number of trainable layers before freezing the conv base: 208\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: \"ViT_BloodClass\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 384, 384, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 12, 12, 768)       2360064   \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 144, 768)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 145, 768)          768       \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 145, 768)         111360    \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 145, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 145, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 145, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 145, 768)         1536      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 768)               0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " BatchNormalization_1 (Batch  (None, 768)              3072      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 64)                49216     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " BatchNormalization_2 (Batch  (None, 32)               128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Pred_blood (Dense)          (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,582,787\n",
      "Trainable params: 87,581,187\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_model = build_ViTModel(fine_tune=False, IMAGE_SIZE=IMAGE_SIZE, Numclass=numclass)\n",
    "vit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "upper-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "learing_rate=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "funky-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "vit_model.compile(loss=loss_smooth,\n",
    "                       optimizer=Adam(learing_rate, decay=learing_rate),\n",
    "                       metrics=[metrics_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "conceptual-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 22s 719ms/step - loss: 1.5160 - accuracy: 0.3833 - val_loss: 1.3012 - val_accuracy: 0.2500\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 1.4766 - accuracy: 0.3875 - val_loss: 1.1705 - val_accuracy: 0.2500\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 15s 987ms/step - loss: 1.4760 - accuracy: 0.3583 - val_loss: 1.4681 - val_accuracy: 0.2500\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 14s 918ms/step - loss: 1.3153 - accuracy: 0.4042 - val_loss: 1.3239 - val_accuracy: 0.2708\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 13s 900ms/step - loss: 1.2268 - accuracy: 0.4167 - val_loss: 1.2848 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history_freeze = vit_model.fit(train_generator,\n",
    "                       epochs = num_epochs, \n",
    "                       validation_data = test_generator,\n",
    "                       callbacks = [metrics, tensorboard_cb]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "steady-tourist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/tohn/HDD/rheology2023/ViTModel/Classification/Blood_Viscosity/3_classes/fold1/R1/models/ViTb32_3Class_fold1_R1.h5'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "infinite-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Save Visiontranformer Model as: /media/tohn/HDD/rheology2023/ViTModel/Classification/Blood_Viscosity/3_classes/fold1/R1/models/ViTb32_3Class_fold1_R1.h5\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "vit_model.save(Model2save)\n",
    "### print\n",
    "print(f\"[INFO]: Save Visiontranformer Model as: {Model2save}\")\n",
    "print(f\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-edmonton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-terminology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-remainder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-ensemble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-faith",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
